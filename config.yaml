training: 

  run: 
    multi_agent: true
    clean_run: false
    fps: 2
  environment:
    env: ??? 
    clip_actions: true
    normalize_actions: true
    env_config: 
      render_mode: rgb_array
      dim_x: 8
      dim_y: 8
      init_display: false
    render_env: false
  rollouts: 
    num_rollout_workers: 20
    num_envs_per_worker: 8 
    rollout_fragment_length: auto
    observation_filter: MeanStdFilter

  debugging: 
    logger_creator: ???
    log_level: INFO


  training:
    train_batch_size: 4096
    model:
      fcnet_hiddens: [  2048, 1024, 512 ]
      free_log_std: true
      vf_share_layers: false
      # use_attention: true
      # The number of transformer units within GTrXL.
      # A transformer unit in GTrXL consists of a) MultiHeadAttention module and
      # b) a position-wise MLP.
      # attention_num_transformer_units: 16
      # The input and output size of each transformer unit.
      # attention_dim: 10
      # # The number of attention heads within the MultiHeadAttention units.
      # attention_num_heads: 4
      # # The dim of a single head (within the MultiHeadAttention units).
      # attention_head_dim: 4
      # # The memory sizes for inference and training.  is the number of timesteps to concat (time axis) and feed into the next transformer unit as inference input. The first transformer unit of your policy will receive this number of past observations (plus the current one), instead.
      # attention_memory_inference: 10
      # attention_memory_training: 10
      # # The output dim of the position-wise MLP.
      # attention_position_wise_mlp_dim: 64
      # # The initial bias values for the 2 GRU gates within a transformer unit.
      # attention_init_gru_gate_bias: 2.0
      # Whether to feed a_{t-n:t-1} to GTrXL (one-hot encoded if discrete).
      # attention_use_n_prev_actions: 3
      # # Whether to feed r_{t-n:t-1} to GTrXL.
      # attention_use_n_prev_rewards: 1

          
    optimizer:
      type: adam

        
    use_critic: true
    use_gae: true
    lambda_: 0.92
    kl_coeff: 0.2

    sgd_minibatch_size: 512 

    num_sgd_iter: 5

    shuffle_sequences: true

    vf_loss_coeff: 0.5

    entropy_coeff: 0.001

    clip_param: 0.3

    kl_target: 0.01
    
    vf_clip_param: 1000.0

  framework:
    framework: torch
    # eager_tracing: true

  resources:
    num_gpus: 1
    num_cpus_per_worker: 1
    num_gpus_per_worker: 0

  # evaluation:
  #   evaluation_interval: 1
  #   evaluation_duration: 10
  #   evaluation_num_workers: 1
  #   evaluation_config: 
  #     render_env: true
  #     deterministic: true
